{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75391d35",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import librosa\n",
    "import librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "from IPython.display import Audio\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.layers import Dense\n",
    "import tensorflow as tf\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e398a91",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5565a29",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"../speech_emotion_dataset\"\n",
    "# audio_dir = \"./Crema\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f0a73af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_listen(audio_path, sample_rate=22050):\n",
    "    # Load the audio\n",
    "    y, sr = librosa.load(audio_path, sr=sample_rate)\n",
    "\n",
    "    # Plot the waveform\n",
    "    plt.figure(figsize=(14, 4))\n",
    "    librosa.display.waveshow(y, sr=sr)\n",
    "    plt.title(f\"Waveform of {audio_path}\")\n",
    "    plt.xlabel(\"Time (s)\")\n",
    "    plt.ylabel(\"Amplitude\")\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "    # Play the audio\n",
    "    return Audio(y, rate=sr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1751fb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Locate the folder with .wav files\n",
    "audio_dir = os.path.join(path, \"Crema\")  # Make sure this folder name matches what you see\n",
    "\n",
    "# List all .wav files\n",
    "audio_files = [f for f in os.listdir(audio_dir) if f.endswith(\".wav\")]\n",
    "print(f\"Total audio files: {len(audio_files)}\")\n",
    "\n",
    "# Mapping of emotion codes to labels\n",
    "emotion_map = {\n",
    "    \"ANG\": \"Angry\",\n",
    "    \"DIS\": \"Disgust\",\n",
    "    \"FEA\": \"Fear\",\n",
    "    \"HAP\": \"Happy\",\n",
    "    \"NEU\": \"Neutral\",\n",
    "    \"SAD\": \"Sad\"\n",
    "}\n",
    "\n",
    "# Extract a sample of one file per emotion\n",
    "samples = {}\n",
    "for file in audio_files:\n",
    "    parts = file.split('_')\n",
    "    emotion_code = parts[2]\n",
    "    if emotion_code in emotion_map and emotion_code not in samples:\n",
    "        samples[emotion_code] = file\n",
    "\n",
    "# Plot and listen to one file per emotion\n",
    "for code, filename in samples.items():\n",
    "    filepath = os.path.join(audio_dir, filename)\n",
    "    signal, sr = librosa.load(filepath, sr=None)\n",
    "    \n",
    "    # Plot waveform\n",
    "    plt.figure(figsize=(10, 3))\n",
    "    librosa.display.waveshow(signal, sr=sr)\n",
    "    plt.title(f\"{emotion_map[code]} - {filename}\")\n",
    "    plt.xlabel(\"Time (s)\")\n",
    "    plt.ylabel(\"Amplitude\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Play audio (if running in Jupyter Notebook)\n",
    "    try:\n",
    "        from IPython.display import Audio, display\n",
    "        display(Audio(filepath))\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "348c90cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(filepath, sr=16000, frame_length=2048, hop_length=512, n_mels=128):\n",
    "    # Load audio\n",
    "    signal, sr = librosa.load(filepath, sr=sr)  # Use desired sampling rate\n",
    "    \n",
    "    # Trim silent edges\n",
    "    signal, _ = librosa.effects.trim(signal)\n",
    "    \n",
    "    # --- Zero Crossing Rate ---\n",
    "    zcr = librosa.feature.zero_crossing_rate(\n",
    "        y=signal, frame_length=frame_length, hop_length=hop_length\n",
    "    )[0]  # shape: (frames,)\n",
    "\n",
    "    # --- Energy (normalized) ---\n",
    "    energy = np.array([\n",
    "        np.sum(signal[i:i+frame_length]**2) / frame_length\n",
    "        for i in range(0, len(signal) - frame_length + 1, hop_length)\n",
    "    ])\n",
    "    \n",
    "    # --- Mel Spectrogram ---\n",
    "    mel_spec = librosa.feature.melspectrogram(\n",
    "        y=signal, sr=sr, n_mels=n_mels,\n",
    "        n_fft=frame_length, hop_length=hop_length\n",
    "    )\n",
    "\n",
    "    mel_spec_db = librosa.power_to_db(mel_spec, ref=np.max)\n",
    "\n",
    "    return zcr, energy, mel_spec_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcfb45a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test on a sample\n",
    "test_file = os.path.join(audio_dir, random.choice(audio_files))\n",
    "zcr, energy, mel_spec = extract_features(test_file )\n",
    "fs1 = zcr , energy\n",
    "fs2 = mel_spec\n",
    "# Plot features\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.plot(zcr)\n",
    "plt.title(\"Zero Crossing Rate\")\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.plot(energy)\n",
    "plt.title(\"Energy\")\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "librosa.display.specshow(mel_spec, sr=16000, x_axis='time', y_axis='mel')\n",
    "plt.colorbar(format='%+2.0f dB')\n",
    "plt.title(\"Mel Spectrogram\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1a3d773",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare containers\n",
    "zcr_list = []\n",
    "energy_list = []\n",
    "mel_spec_list = []\n",
    "labels = []\n",
    "\n",
    "valid_emotions = {\"ANG\", \"DIS\", \"FEA\", \"HAP\", \"NEU\", \"SAD\"}\n",
    "\n",
    "# Loop through files\n",
    "for file in tqdm(audio_files):\n",
    "    parts = file.split('_')\n",
    "    emotion_code = parts[2]\n",
    "\n",
    "    if emotion_code not in valid_emotions:\n",
    "        continue  # skip unknown emotions\n",
    "\n",
    "    filepath = os.path.join(audio_dir, file)\n",
    "    \n",
    "    try:\n",
    "        zcr, energy, mel_spec = extract_features(filepath)\n",
    "        \n",
    "        zcr_list.append(zcr)\n",
    "        energy_list.append(energy)\n",
    "        mel_spec_list.append(mel_spec)\n",
    "        labels.append(emotion_code)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Failed for {file}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44befa75",
   "metadata": {},
   "outputs": [],
   "source": [
    "X =zcr_list, energy_list, mel_spec_list\n",
    "print(len(zcr_list), len(energy_list), len(mel_spec_list))\n",
    "\n",
    "le = LabelEncoder()\n",
    "label_array = le.fit_transform(labels)\n",
    "\n",
    "# Get mapping\n",
    "label_map = dict(zip(le.classes_, le.transform(le.classes_)))\n",
    "print(\"Label mapping:\", label_map)\n",
    "label_array.shape\n",
    "print(label_array.shape)\n",
    "\n",
    "# Convert to DataFrame\n",
    "df = pd.DataFrame({\n",
    "    'zcr': zcr_list,\n",
    "    'energy': energy_list,\n",
    "    'mel_spec': mel_spec_list,\n",
    "    'label': label_array\n",
    "})\n",
    "\n",
    "X = df.drop(columns=['label'])\n",
    "y = df['label']\n",
    "\n",
    "print(\"Shape of features:\", X.shape)\n",
    "print(\"Shape of labels:\", y.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6685124",
   "metadata": {},
   "source": [
    "### Splitting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ff146e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Train+Val (70%) and Test (30%)\n",
    "X_temp, X_test, y_temp, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.3,\n",
    "    stratify=y,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# 2. From Train+Val, get 5% as validation\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_temp, y_temp,\n",
    "    test_size=0.05,  # 5% of 70% â‰ˆ 3.5% of total data\n",
    "    stratify=y_temp,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Show shapes\n",
    "print(\"Train shape:\", X_train.shape)\n",
    "print(\"Validation shape:\", X_val.shape)\n",
    "print(\"Test shape:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ca17950",
   "metadata": {},
   "source": [
    "### Create the feature space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0dc8994",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"First feature Space\"\"\" \n",
    "X_train1 = X_train[X_train.columns[0:2]]\n",
    "X_val1   = X_val[X_val.columns[0:2]]\n",
    "X_test1  = X_test[X_test.columns[0:2]]\n",
    "\n",
    "\"\"\"Second feature space\"\"\"\n",
    "X_train2 = X_train[X_train.columns[2:]]\n",
    "X_val2   = X_val[X_val.columns[2:]]\n",
    "X_test2  = X_test[X_test.columns[2:]]\n",
    "\n",
    "print(\"Train shape1:\", X_train1.shape)\n",
    "print(\"Validation shape1:\", X_val1.shape)\n",
    "print(\"Test shape1:\", X_test1.shape)\n",
    "\n",
    "print(\"Train shape2:\", X_train2.shape)\n",
    "print(\"Validation shape2:\", X_val2.shape)\n",
    "print(\"Test shape2:\", X_test2.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81671c61",
   "metadata": {},
   "source": [
    "### Prepare Data for Model Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47113b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# Pad 1D features\n",
    "def stack_and_pad_1d(features1, features2, max_len=400):\n",
    "    x1 = pad_sequences(features1, maxlen=max_len, padding='post', dtype='float32')\n",
    "    x2 = pad_sequences(features2, maxlen=max_len, padding='post', dtype='float32')\n",
    "    return np.stack([x1, x2], axis=-1)\n",
    "\n",
    "X_train1_padded = stack_and_pad_1d(X_train1['zcr'], X_train1['energy'])\n",
    "X_val1_padded = stack_and_pad_1d(X_val1['zcr'], X_val1['energy'])\n",
    "X_test1_padded = stack_and_pad_1d(X_test1['zcr'], X_test1['energy'])\n",
    "\n",
    "# Pad mel spectrograms\n",
    "def pad_melspec(mels, max_time=400):\n",
    "    padded = []\n",
    "    for m in mels:\n",
    "        if m.shape[1] < max_time:\n",
    "            pad_width = max_time - m.shape[1]\n",
    "            m_padded = np.pad(m, ((0, 0), (0, pad_width)), mode='constant')\n",
    "        else:\n",
    "            m_padded = m[:, :max_time]\n",
    "        padded.append(m_padded)\n",
    "    return np.array(padded)[..., np.newaxis]\n",
    "\n",
    "X_train2_padded = pad_melspec(X_train2['mel_spec'])\n",
    "X_val2_padded = pad_melspec(X_val2['mel_spec'])\n",
    "X_test2_padded = pad_melspec(X_test2['mel_spec'])\n",
    "\n",
    "# Convert labels\n",
    "y_train_arr = tf.keras.utils.to_categorical(y_train)\n",
    "y_val_arr = tf.keras.utils.to_categorical(y_val)\n",
    "y_test_arr = tf.keras.utils.to_categorical(y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3d30e3d",
   "metadata": {},
   "source": [
    "## Define CNN Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1b2341f",
   "metadata": {},
   "source": [
    "### 1D CNN (ZCR + Energy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d94747e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_1d_cnn(input_shape, num_classes):\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Input(shape=input_shape),\n",
    "        tf.keras.layers.Conv1D(512, kernel_size=5, strides=1, padding='same', activation='relu'),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.MaxPooling1D(pool_size=5,strides=2,padding='same'),\n",
    "        tf.keras.layers.Conv1D(512, kernel_size=5, strides=1, padding='same', activation='relu'),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.MaxPooling1D(pool_size=5,strides=2,padding='same'),\n",
    "        tf.keras.layers.Conv1D(256, kernel_size=5, strides=1, padding='same', activation='relu'),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.MaxPooling1D(pool_size=5,strides=2,padding='same'),\n",
    "        tf.keras.layers.Conv1D(256, kernel_size=5, strides=1, padding='same', activation='relu'),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.MaxPooling1D(pool_size=5,strides=2,padding='same'),\n",
    "        tf.keras.layers.Conv1D(128, kernel_size=5, strides=1, padding='same', activation='relu'),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.MaxPooling1D(pool_size=5,strides=2,padding='same'),\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dense(512, activation='relu'),\n",
    "        tf.keras.layers.Dropout(0.3),\n",
    "        tf.keras.layers.Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be66e829",
   "metadata": {},
   "source": [
    "### 2D CNN (Mel Spectrogram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc8020c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_2d_cnn(input_shape, num_classes):\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Input(shape=input_shape),\n",
    "        tf.keras.layers.Conv2D(512, (5, 5), strides=1, padding='same', activation='relu'),\n",
    "        tf.keras.layers.MaxPooling2D(pool_size=(5, 5),strides=2,padding='same'),\n",
    "        tf.keras.layers.Conv2D(512, (5, 5), strides=1, padding='same', activation='relu'),\n",
    "        tf.keras.layers.MaxPooling2D(pool_size=(5, 5),strides=2,padding='same'),\n",
    "        tf.keras.layers.Conv2D(256, (5, 5), strides=1, padding='same', activation='relu'),\n",
    "        tf.keras.layers.MaxPooling2D(pool_size=(5, 5),strides=2,padding='same'),\n",
    "        tf.keras.layers.Conv2D(256, (5, 5), strides=1, padding='same', activation='relu'),\n",
    "        tf.keras.layers.MaxPooling2D(pool_size=(5, 5),strides=2,padding='same'),\n",
    "        tf.keras.layers.Conv2D(128, (5, 5), strides=1, padding='same', activation='relu'),\n",
    "        tf.keras.layers.MaxPooling2D(pool_size=(5, 5),strides=2,padding='same'),\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dense(512, activation='relu'),\n",
    "        tf.keras.layers.Dropout(0.3),\n",
    "        tf.keras.layers.Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c435812d",
   "metadata": {},
   "source": [
    "### Train the 1D CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e200f9d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "    EarlyStopping(monitor= 'val_accuracy', patience=5, restore_best_weights=True, mode ='max'),\n",
    "    ReduceLROnPlateau(monitor='val_accuracy',patience=3,verbose=1,factor=0.5,min_lr=0.00001)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95d00a85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train 1D CNN\n",
    "model_1d = build_1d_cnn(X_train1_padded.shape[1:], 6)\n",
    "model_1d.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model_1d.summary()\n",
    "history_1D = model_1d.fit(X_train1_padded, y_train_arr, epochs=100, batch_size=32, \n",
    "             validation_data=(X_val1_padded, y_val_arr), callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42bb4f73",
   "metadata": {},
   "source": [
    "### Train the 2D CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9409b570",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train 2D CNN\n",
    "model_2d = build_2d_cnn(X_train2_padded.shape[1:], 6)\n",
    "model_2d.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model_2d.summary()\n",
    "history_2D = model_2d.fit(X_train2_padded, y_train_arr, epochs=30, batch_size=32, \n",
    "             validation_data=(X_val2_padded, y_val_arr), callbacks=callbacks)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb710892",
   "metadata": {},
   "source": [
    "## Models Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "158829d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train accuracy\n",
    "train_acc_1d = history_1D.history['accuracy']\n",
    "train_acc_2d = history_2D.history['accuracy']\n",
    "# validation accuracy\n",
    "val_acc_1d = history_1D.history['val_accuracy']\n",
    "val_acc_2d = history_2D.history['val_accuracy']\n",
    "# train loss\n",
    "train_loss_1d = history_1D.history['loss']\n",
    "train_loss_2d = history_2D.history['loss']\n",
    "# validation loss\n",
    "val_loss_1d = history_1D.history['val_loss']\n",
    "val_loss_2d = history_2D.history['val_loss']\n",
    "\n",
    "print(\"Train accuracy 1D:\", train_acc_1d)\n",
    "print(\"Validation accuracy 1D:\", val_acc_1d)\n",
    "\n",
    "print(\"Train accuracy 2D:\", train_acc_2d)\n",
    "print(\"Validation accuracy 2D:\", val_acc_2d)\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(train_acc_1d, label='Train 1D')\n",
    "plt.plot(val_acc_1d, label='Validation 1D')\n",
    "plt.plot(train_acc_2d, label='Train 2D')\n",
    "plt.plot(val_acc_2d, label='Validation 2D')\n",
    "plt.title('Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "\n",
    "plt.legend()\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(train_loss_1d, label='Train 1D')\n",
    "plt.plot(val_loss_1d, label='Validation 1D')\n",
    "plt.plot(train_loss_2d, label='Train 2D')\n",
    "plt.plot(val_loss_2d, label='Validation 2D')\n",
    "plt.title('Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
